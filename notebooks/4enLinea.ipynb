{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "inXI2Dnjv_A4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dhI70Pdvv_BA"
      },
      "outputs": [],
      "source": [
        "def iaTurn(board):\n",
        "    print(board)\n",
        "    normalize(board)\n",
        "    return int(input(\"turno\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ot18Pe1v_BB"
      },
      "source": [
        "Game : Designed by https://github.com/KeithGalli/Connect4-Python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAhjUAQWv_BE",
        "outputId": "c0c86d0d-2287-47e1-bdd0-e5af5b9e0ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.12.11)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pygame\n",
        "import sys\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6VIqdaBv_BF"
      },
      "source": [
        "Juego con IA implementada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nLwnAOycv_BJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pygame\n",
        "\n",
        "# Colores\n",
        "BLUE = (0, 0, 255)\n",
        "BLACK = (0, 0, 0)\n",
        "RED = (255, 0, 0)\n",
        "YELLOW = (255, 255, 0)\n",
        "\n",
        "# Dimensiones del tablero\n",
        "ROW_COUNT = 6\n",
        "COLUMN_COUNT = 7\n",
        "\n",
        "# Variables globales\n",
        "board = None\n",
        "game_over = None\n",
        "turn = None\n",
        "winner = None\n",
        "screen = None\n",
        "SQUARESIZE = None\n",
        "size = None\n",
        "width = None\n",
        "height = None\n",
        "RADIUS = None\n",
        "myfont = None\n",
        "\n",
        "\n",
        "def normalize(board):\n",
        "    \"\"\"Convierte el tablero a formato imagen (6x7x1).\"\"\"\n",
        "    return board.reshape((ROW_COUNT, COLUMN_COUNT, 1))\n",
        "\n",
        "\n",
        "def reset():\n",
        "    \"\"\"Reinicia el juego y crea un tablero nuevo.\"\"\"\n",
        "    global board, game_over, winner, turn\n",
        "    global screen, SQUARESIZE, size, width, height, RADIUS, myfont\n",
        "\n",
        "    board = create_board()\n",
        "    print_board(board)\n",
        "    game_over = False\n",
        "    winner = None\n",
        "    turn = 1  # ahora arranca el jugador 1 (pieza 1)\n",
        "\n",
        "    pygame.init()\n",
        "\n",
        "    SQUARESIZE = 100\n",
        "    width = COLUMN_COUNT * SQUARESIZE\n",
        "    height = (ROW_COUNT + 1) * SQUARESIZE\n",
        "    size = (width, height)\n",
        "    RADIUS = int(SQUARESIZE / 2 - 5)\n",
        "\n",
        "    screen = pygame.display.set_mode(size)\n",
        "    draw_board(board)\n",
        "    pygame.display.update()\n",
        "\n",
        "    myfont = pygame.font.SysFont(\"monospace\", 75)\n",
        "\n",
        "\n",
        "def create_board():\n",
        "    \"\"\"Crea un tablero vacío.\"\"\"\n",
        "    return np.zeros((ROW_COUNT, COLUMN_COUNT))\n",
        "\n",
        "\n",
        "def drop_piece(board, row, col, piece):\n",
        "    \"\"\"Coloca una ficha en el tablero.\"\"\"\n",
        "    board[row][col] = piece\n",
        "\n",
        "\n",
        "def is_valid_location(board, col):\n",
        "    \"\"\"Revisa si se puede jugar en esa columna.\"\"\"\n",
        "    return board[ROW_COUNT - 1][col] == 0\n",
        "\n",
        "\n",
        "def get_next_open_row(board, col):\n",
        "    \"\"\"Devuelve la próxima fila libre en la columna.\"\"\"\n",
        "    for r in range(ROW_COUNT):\n",
        "        if board[r][col] == 0:\n",
        "            return r\n",
        "\n",
        "\n",
        "def print_board(board):\n",
        "    \"\"\"Imprime el tablero en consola.\"\"\"\n",
        "    print(np.flip(board, 0))\n",
        "\n",
        "\n",
        "def winning_move(board, piece):\n",
        "    \"\"\"Revisa si el jugador actual ganó.\"\"\"\n",
        "    # Horizontal\n",
        "    for c in range(COLUMN_COUNT - 3):\n",
        "        for r in range(ROW_COUNT):\n",
        "            if all(board[r][c + i] == piece for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    # Vertical\n",
        "    for c in range(COLUMN_COUNT):\n",
        "        for r in range(ROW_COUNT - 3):\n",
        "            if all(board[r + i][c] == piece for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    # Diagonal positiva\n",
        "    for c in range(COLUMN_COUNT - 3):\n",
        "        for r in range(ROW_COUNT - 3):\n",
        "            if all(board[r + i][c + i] == piece for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    # Diagonal negativa\n",
        "    for c in range(COLUMN_COUNT - 3):\n",
        "        for r in range(3, ROW_COUNT):\n",
        "            if all(board[r - i][c + i] == piece for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def draw_board(board):\n",
        "    \"\"\"Dibuja el tablero con pygame.\"\"\"\n",
        "    global screen, SQUARESIZE, RADIUS, width, height\n",
        "\n",
        "    for c in range(COLUMN_COUNT):\n",
        "        for r in range(ROW_COUNT):\n",
        "            pygame.draw.rect(\n",
        "                screen,\n",
        "                BLUE,\n",
        "                (c * SQUARESIZE, r * SQUARESIZE + SQUARESIZE, SQUARESIZE, SQUARESIZE),\n",
        "            )\n",
        "            pygame.draw.circle(\n",
        "                screen,\n",
        "                BLACK,\n",
        "                (int(c * SQUARESIZE + SQUARESIZE / 2),\n",
        "                 int(r * SQUARESIZE + SQUARESIZE + SQUARESIZE / 2)),\n",
        "                RADIUS,\n",
        "            )\n",
        "\n",
        "    for c in range(COLUMN_COUNT):\n",
        "        for r in range(ROW_COUNT):\n",
        "            if board[r][c] == 1:\n",
        "                pygame.draw.circle(\n",
        "                    screen,\n",
        "                    RED,\n",
        "                    (int(c * SQUARESIZE + SQUARESIZE / 2),\n",
        "                     height - int(r * SQUARESIZE + SQUARESIZE / 2)),\n",
        "                    RADIUS,\n",
        "                )\n",
        "            elif board[r][c] == 2:\n",
        "                pygame.draw.circle(\n",
        "                    screen,\n",
        "                    YELLOW,\n",
        "                    (int(c * SQUARESIZE + SQUARESIZE / 2),\n",
        "                     height - int(r * SQUARESIZE + SQUARESIZE / 2)),\n",
        "                    RADIUS,\n",
        "                )\n",
        "\n",
        "    pygame.display.update()\n",
        "\n",
        "\n",
        "def moove(col):\n",
        "    \"\"\"Realiza un movimiento en la columna indicada.\"\"\"\n",
        "    global board, turn, game_over, winner\n",
        "\n",
        "    if not game_over:\n",
        "        piece = turn  # ahora el turno ES directamente la pieza (1 o 2)\n",
        "\n",
        "        if is_valid_location(board, col):\n",
        "            row = get_next_open_row(board, col)\n",
        "            drop_piece(board, row, col, piece)\n",
        "\n",
        "            if winning_move(board, piece):\n",
        "                game_over = True\n",
        "                winner = piece\n",
        "\n",
        "            print_board(board)\n",
        "            draw_board(board)\n",
        "\n",
        "            # alterna entre jugador 1 (pieza 1) y jugador 2 (pieza 2)\n",
        "            turn = 1 if turn == 2 else 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W7r8M7-Ov_BN"
      },
      "outputs": [],
      "source": [
        "class ConnectFourEnv:\n",
        "    \"\"\"\n",
        "    Entorno de Connect Four para entrenamiento de IA.\n",
        "    Usa:\n",
        "      - board: tablero actual\n",
        "      - turn: pieza que mueve actualmente (1 o 2)\n",
        "      - game_over: si la partida terminó\n",
        "      - winner: quién ganó\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reinicia el juego.\"\"\"\n",
        "        self.board = np.zeros((ROW_COUNT, COLUMN_COUNT), dtype=np.int8)\n",
        "        self.turn = 1            # turno = pieza directamente\n",
        "        self.game_over = False\n",
        "        self.winner = None\n",
        "        return self.get_state()\n",
        "\n",
        "    def valid_actions(self):\n",
        "        \"\"\"Columnas en las que se puede jugar.\"\"\"\n",
        "        return [c for c in range(COLUMN_COUNT) if self.board[ROW_COUNT - 1][c] == 0]\n",
        "\n",
        "    def board_full(self):\n",
        "        \"\"\"Revisa si el tablero está lleno.\"\"\"\n",
        "        return len(self.valid_actions()) == 0\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Realiza un movimiento.\n",
        "        action: columna donde poner la ficha\n",
        "        Devuelve: next_state, reward, done, info\n",
        "        \"\"\"\n",
        "        if self.game_over:\n",
        "            raise ValueError(\"La partida terminó, resetear el entorno.\")\n",
        "\n",
        "        if action not in self.valid_actions():\n",
        "            # castigo por jugar en columna inválida\n",
        "            return self.get_state(), -10.0, True, {\"invalid\": True}\n",
        "\n",
        "        # ubica la ficha\n",
        "        row = get_next_open_row(self.board, action)\n",
        "        drop_piece(self.board, row, action, self.turn)\n",
        "\n",
        "        # revisa ganador\n",
        "        if winning_move(self.board, self.turn):\n",
        "            self.game_over = True\n",
        "            self.winner = self.turn\n",
        "            reward = 1.0  # recompensa por ganar\n",
        "            done = True\n",
        "        elif self.board_full():\n",
        "            self.game_over = True\n",
        "            self.winner = None\n",
        "            reward = 0.0  # empate\n",
        "            done = True\n",
        "        else:\n",
        "            reward = 0.0\n",
        "            done = False\n",
        "            # alterna turno\n",
        "            self.turn = opponent_piece(self.turn)\n",
        "\n",
        "        return self.get_state(), reward, done, {}\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"Devuelve el estado canónico para la red neuronal.\"\"\"\n",
        "        return canonical_state(self.board, self.turn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento de modelo"
      ],
      "metadata": {
        "id": "KBLNteZfyV_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Si usás TF 2.x:\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers, models, optimizers\n"
      ],
      "metadata": {
        "id": "4iSYhlp8xqHF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valid_actions_from_board(b):\n",
        "    return [c for c in range(COLUMN_COUNT) if b[ROW_COUNT - 1][c] == 0]\n",
        "\n",
        "\n",
        "def board_full(b):\n",
        "    return len(valid_actions_from_board(b)) == 0\n",
        "\n",
        "\n",
        "def opponent_piece(piece):\n",
        "    return 2 if piece == 1 else 1\n",
        "\n",
        "\n",
        "def canonical_state(b, turn):\n",
        "    me = turn            # ahora turn ya es 1 o 2\n",
        "    you = opponent_piece(me)\n",
        "    s = np.zeros_like(b, dtype=np.float32)\n",
        "    s[b == me] = 1.0\n",
        "    s[b == you] = -1.0\n",
        "    return s.reshape((ROW_COUNT, COLUMN_COUNT, 1))\n"
      ],
      "metadata": {
        "id": "iHELNYC7yXp0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import random\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, env, gamma=0.99, lr=0.001, batch_size=64, memory_size=5000):\n",
        "        self.env = env\n",
        "        self.gamma = gamma\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.memory = deque(maxlen=memory_size)\n",
        "\n",
        "        # Red neuronal\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(64, (2,2), activation='relu', input_shape=(ROW_COUNT, COLUMN_COUNT, 1)))\n",
        "        model.add(layers.Conv2D(128, (2,2), activation='relu'))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(128, activation='relu'))\n",
        "        model.add(layers.Dense(COLUMN_COUNT, activation='linear'))  # 7 salidas, una por columna\n",
        "        model.compile(optimizer=optimizers.Adam(learning_rate=self.lr), loss='mse')\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state, epsilon=0.1):\n",
        "        \"\"\"ε-greedy policy\"\"\"\n",
        "        if np.random.rand() < epsilon:\n",
        "            return random.choice(self.env.valid_actions())\n",
        "        q_values = self.model.predict(state[np.newaxis, ...], verbose=0)[0]\n",
        "        # solo consideramos columnas válidas\n",
        "        valid_cols = self.env.valid_actions()\n",
        "        q_values_invalid = [-np.inf if c not in valid_cols else q_values[c] for c in range(COLUMN_COUNT)]\n",
        "        return int(np.argmax(q_values_invalid))\n",
        "\n",
        "    def replay(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "        states = []\n",
        "        targets = []\n",
        "        for state, action, reward, next_state, done in batch:\n",
        "            target = self.model.predict(state[np.newaxis, ...], verbose=0)[0]\n",
        "            if done:\n",
        "                target[action] = reward\n",
        "            else:\n",
        "                t_next = self.model.predict(next_state[np.newaxis, ...], verbose=0)[0]\n",
        "                target[action] = reward + self.gamma * np.max(t_next)\n",
        "            states.append(state)\n",
        "            targets.append(target)\n",
        "        self.model.fit(np.array(states), np.array(targets), epochs=1, verbose=0)\n"
      ],
      "metadata": {
        "id": "6FZzsBl81cnv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros de entrenamiento\n",
        "EPISODES = 1000      # cantidad de partidas\n",
        "EPSILON_START = 1.0  # exploración inicial\n",
        "EPSILON_END = 0.05   # exploración mínima\n",
        "EPSILON_DECAY = 0.9995\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Creamos entorno y agente\n",
        "env = ConnectFourEnv()\n",
        "agent = DQNAgent(env, gamma=GAMMA, batch_size=BATCH_SIZE)\n",
        "\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "for episode in range(1, EPISODES + 1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Acción del agente actual\n",
        "        action = agent.act(state, epsilon)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Guardamos transición en memoria\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "\n",
        "        # Actualizamos estado\n",
        "        state = next_state\n",
        "\n",
        "    # Entrenamos la red después de la partida\n",
        "    agent.replay()\n",
        "\n",
        "    # Decay de epsilon\n",
        "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
        "\n",
        "    # Info cada 100 partidas\n",
        "    if episode % 10 == 0:\n",
        "        print(f\"Episode {episode}, Epsilon {epsilon:.3f}, Winner: {env.winner}\")\n"
      ],
      "metadata": {
        "id": "cQPg_yUp1jxm",
        "outputId": "62335c0c-6686-4a7f-a02b-684bedf72a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 10, Epsilon 0.995, Winner: 1\n",
            "Episode 20, Epsilon 0.990, Winner: 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-465924361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Entrenamos la red después de la partida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Decay de epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-645063383.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mt_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iaTurn(agent, board, turn):\n",
        "    \"\"\"\n",
        "    Devuelve la columna elegida por la IA para jugar.\n",
        "\n",
        "    Parámetros:\n",
        "        agent : DQNAgent entrenado\n",
        "        board : np.array del tablero actual (6x7)\n",
        "        turn  : pieza que mueve (1 o 2)\n",
        "\n",
        "    Retorna:\n",
        "        col : columna elegida por la IA\n",
        "    \"\"\"\n",
        "    # Obtenemos el estado canónico desde la perspectiva de quien mueve\n",
        "    state = canonical_state(board, turn)\n",
        "\n",
        "    # ε=0 para que siempre elija la mejor acción según la red\n",
        "    q_values = agent.model.predict(state[np.newaxis, ...], verbose=0)[0]\n",
        "\n",
        "    # Solo consideramos columnas válidas\n",
        "    valid_cols = [c for c in range(COLUMN_COUNT) if board[ROW_COUNT-1][c] == 0]\n",
        "    q_values_filtered = [-np.inf if c not in valid_cols else q_values[c] for c in range(COLUMN_COUNT)]\n",
        "\n",
        "    # Elegimos la columna con mayor Q-value\n",
        "    col = int(np.argmax(q_values_filtered))\n",
        "    return col\n"
      ],
      "metadata": {
        "id": "R-DyJW432J8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BLUE = (0,0,255)\n",
        "BLACK = (0,0,0)\n",
        "RED = (255,0,0)\n",
        "YELLOW = (255,255,0)\n",
        "\n",
        "ROW_COUNT = 6\n",
        "COLUMN_COUNT = 7\n",
        "\n",
        "def create_board():\n",
        "    board = np.zeros((ROW_COUNT,COLUMN_COUNT))\n",
        "    return board\n",
        "\n",
        "def drop_piece(board, row, col, piece):\n",
        "    board[row][col] = piece\n",
        "\n",
        "def is_valid_location(board, col):\n",
        "    return board[ROW_COUNT-1][col] == 0\n",
        "\n",
        "def get_next_open_row(board, col):\n",
        "    for r in range(ROW_COUNT):\n",
        "        if board[r][col] == 0:\n",
        "            return r\n",
        "\n",
        "def print_board(board):\n",
        "    print(np.flip(board, 0))\n",
        "\n",
        "def winning_move(board, piece):\n",
        "    # Check horizontal locations for win\n",
        "    for c in range(COLUMN_COUNT-3):\n",
        "        for r in range(ROW_COUNT):\n",
        "            if board[r][c] == piece and board[r][c+1] == piece and board[r][c+2] == piece and board[r][c+3] == piece:\n",
        "                return True\n",
        "\n",
        "    # Check vertical locations for win\n",
        "    for c in range(COLUMN_COUNT):\n",
        "        for r in range(ROW_COUNT-3):\n",
        "            if board[r][c] == piece and board[r+1][c] == piece and board[r+2][c] == piece and board[r+3][c] == piece:\n",
        "                return True\n",
        "\n",
        "    # Check positively sloped diaganols\n",
        "    for c in range(COLUMN_COUNT-3):\n",
        "        for r in range(ROW_COUNT-3):\n",
        "            if board[r][c] == piece and board[r+1][c+1] == piece and board[r+2][c+2] == piece and board[r+3][c+3] == piece:\n",
        "                return True\n",
        "\n",
        "    # Check negatively sloped diaganols\n",
        "    for c in range(COLUMN_COUNT-3):\n",
        "        for r in range(3, ROW_COUNT):\n",
        "            if board[r][c] == piece and board[r-1][c+1] == piece and board[r-2][c+2] == piece and board[r-3][c+3] == piece:\n",
        "                return True\n",
        "\n",
        "def draw_board(board):\n",
        "    for c in range(COLUMN_COUNT):\n",
        "        for r in range(ROW_COUNT):\n",
        "            pygame.draw.rect(screen, BLUE, (c*SQUARESIZE, r*SQUARESIZE+SQUARESIZE, SQUARESIZE, SQUARESIZE))\n",
        "            pygame.draw.circle(screen, BLACK, (int(c*SQUARESIZE+SQUARESIZE/2), int(r*SQUARESIZE+SQUARESIZE+SQUARESIZE/2)), RADIUS)\n",
        "\n",
        "    for c in range(COLUMN_COUNT):\n",
        "        for r in range(ROW_COUNT):\n",
        "            if board[r][c] == 1:\n",
        "                pygame.draw.circle(screen, RED, (int(c*SQUARESIZE+SQUARESIZE/2), height-int(r*SQUARESIZE+SQUARESIZE/2)), RADIUS)\n",
        "            elif board[r][c] == 2:\n",
        "                pygame.draw.circle(screen, YELLOW, (int(c*SQUARESIZE+SQUARESIZE/2), height-int(r*SQUARESIZE+SQUARESIZE/2)), RADIUS)\n",
        "    pygame.display.update()\n",
        "\n",
        "\n",
        "board = create_board()\n",
        "print_board(board)\n",
        "game_over = False\n",
        "turn = 0\n",
        "\n",
        "pygame.init()\n",
        "\n",
        "SQUARESIZE = 100\n",
        "\n",
        "width = COLUMN_COUNT * SQUARESIZE\n",
        "height = (ROW_COUNT+1) * SQUARESIZE\n",
        "\n",
        "size = (width, height)\n",
        "\n",
        "RADIUS = int(SQUARESIZE/2 - 5)\n",
        "\n",
        "screen = pygame.display.set_mode(size)\n",
        "draw_board(board)\n",
        "pygame.display.update()\n",
        "\n",
        "myfont = pygame.font.SysFont(\"monospace\", 75)\n",
        "\n",
        "while not game_over:\n",
        "    if turn==1:\n",
        "            col = iaTurn(agent, board, turn)\n",
        "\n",
        "            if is_valid_location(board, col):\n",
        "                row = get_next_open_row(board, col)\n",
        "                drop_piece(board, row, col, 2)\n",
        "\n",
        "                if winning_move(board, 2):\n",
        "                    label = myfont.render(\"IA wins!!\", 1, YELLOW)\n",
        "                    screen.blit(label, (40,10))\n",
        "                    game_over = True\n",
        "            print_board(board)\n",
        "            draw_board(board)\n",
        "            turn += 1\n",
        "            turn = turn % 2\n",
        "\n",
        "            if game_over:\n",
        "                pygame.time.wait(3000)\n",
        "    else:\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                sys.exit()\n",
        "\n",
        "            if event.type == pygame.MOUSEMOTION:\n",
        "                pygame.draw.rect(screen, BLACK, (0,0, width, SQUARESIZE))\n",
        "                posx = event.pos[0]\n",
        "                if turn == 0:\n",
        "                    pygame.draw.circle(screen, RED, (posx, int(SQUARESIZE/2)), RADIUS)\n",
        "                else:\n",
        "                    pygame.draw.circle(screen, YELLOW, (posx, int(SQUARESIZE/2)), RADIUS)\n",
        "            pygame.display.update()\n",
        "\n",
        "            if event.type == pygame.MOUSEBUTTONDOWN:\n",
        "                pygame.draw.rect(screen, BLACK, (0,0, width, SQUARESIZE))\n",
        "                #print(event.pos)\n",
        "                # Ask for Player 1 Input\n",
        "                if turn == 0:\n",
        "                    posx = event.pos[0]\n",
        "                    print(posx)\n",
        "                    col = int(math.floor(posx/SQUARESIZE))\n",
        "                    print(col)\n",
        "                    if is_valid_location(board, col):\n",
        "                        row = get_next_open_row(board, col)\n",
        "                        drop_piece(board, row, col, 1)\n",
        "\n",
        "                        if winning_move(board, 1):\n",
        "                            label = myfont.render(\"Player 1 wins!!\", 1, RED)\n",
        "                            screen.blit(label, (40,10))\n",
        "                            game_over = True\n",
        "                    print_board(board)\n",
        "                    draw_board(board)\n",
        "                    turn += 1\n",
        "                    turn = turn % 2\n",
        "\n",
        "                    if game_over:\n",
        "                        pygame.time.wait(3000)\n",
        "\n",
        "            else:\n",
        "                continue\n"
      ],
      "metadata": {
        "id": "3gEjVD772SqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}