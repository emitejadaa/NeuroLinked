{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "mount_file_id": "1IDKibQ1xT08IngN3h84rJ-0tBwMDfjnh",
      "authorship_tag": "ABX9TyO4OUdGRCYhzqLE+JCvV2mg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emitejadaa/NeuroLinked/blob/main/notebooks/EEG_motor_imaginery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6v_R4h2qv5EW"
      },
      "outputs": [],
      "source": [
        "!pip install -q --no-cache-dir mne lightning torchmetrics opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorboard tensorboardX tensorboard_logger"
      ],
      "metadata": {
        "id": "OxmvHJSipY70",
        "outputId": "02708ac7-9f7e-417c-9e3d-ce70eaab2b50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.12/dist-packages (2.6.4)\n",
            "Requirement already satisfied: tensorboard_logger in /usr/local/lib/python3.12/dist-packages (0.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard) (11.3.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (6.32.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from tensorboard_logger) (1.17.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard_logger) (1.16.2)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "from mne.io import concatenate_raws\n",
        "\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import cv2\n",
        "import random\n",
        "import string\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import lightning as L\n",
        "from lightning.pytorch import Trainer, seed_everything\n",
        "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "from torchmetrics.classification import Accuracy\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['axes.facecolor'] = 'lightgray'"
      ],
      "metadata": {
        "id": "Ilo34Sf-wqeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aKKGaj5cyCsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/Colab-Datset/eegmmidb/\""
      ],
      "metadata": {
        "id": "uaTGFj2rx7iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import re\n",
        "import numpy as np\n",
        "import mne\n",
        "from mne.io import concatenate_raws\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "N_SUBJECT = 109\n",
        "BASELINE_EYE_OPEN = [1]\n",
        "BASELINE_EYE_CLOSED = [2]\n",
        "OPEN_CLOSE_LEFT_RIGHT_FIST = [3, 7, 11]\n",
        "IMAGINE_OPEN_CLOSE_LEFT_RIGHT_FIST = [4, 8, 12]\n",
        "OPEN_CLOSE_BOTH_FIST = [5, 9, 13]\n",
        "IMAGINE_OPEN_CLOSE_BOTH_FIST = [6, 10, 14]\n",
        "\n",
        "RUN_LEFT = [4, 8, 12]\n",
        "RUN_REST = [1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14]\n",
        "\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Colab-Dataset/eegmidb/MNE-eegbci-data/files\")\n",
        "\n",
        "edf_files = list(DATA_ROOT.rglob(\"*.edf\"))\n",
        "pat = re.compile(r\"[Ss](\\d{3})[Rr](\\d{2})\\.edf$\")\n",
        "\n",
        "paths_left, paths_rest = [], []\n",
        "for p in edf_files:\n",
        "    m = pat.search(p.name)\n",
        "    if not m:\n",
        "        continue\n",
        "    subj = int(m.group(1))\n",
        "    run = int(m.group(2))\n",
        "    if 1 <= subj <= (N_SUBJECT - 30):\n",
        "        if run in RUN_LEFT:\n",
        "            paths_left.append(p)\n",
        "        elif run in RUN_REST:\n",
        "            paths_rest.append(p)\n",
        "\n",
        "def sort_key(p):\n",
        "    return (int(p.name[1:4]), int(p.name[5:7]))\n",
        "\n",
        "paths_left = sorted(paths_left, key=sort_key)\n",
        "paths_rest = sorted(paths_rest, key=sort_key)\n",
        "\n",
        "if not(paths_left) and not(paths_rest):\n",
        "    raise FileNotFoundError(\n",
        "        f\"No se encontraron archivos EDF en {DATA_ROOT}. Comprueba la ruta y la estructura de carpetas.\"\n",
        "    )\n",
        "\n",
        "def process_file_build_xy(edf_path):\n",
        "    # Cargar el EDF\n",
        "    raw = mne.io.read_raw_edf(str(edf_path), preload=True, stim_channel='auto', verbose='WARNING')\n",
        "\n",
        "    eeg_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
        "    eeg_inds = eeg_inds[:32]\n",
        "    events, event_id_map = mne.events_from_annotations(raw)\n",
        "\n",
        "    ep = mne.Epochs(\n",
        "        raw, events,\n",
        "        tmin=1, tmax=4.1,\n",
        "        proj=False,\n",
        "        picks=eeg_inds,\n",
        "        baseline=None,\n",
        "        preload=True,\n",
        "        verbose='WARNING'\n",
        "    )\n",
        "\n",
        "    X_file = (ep.get_data() * 1e3).astype(np.float32)\n",
        "\n",
        "    m = pat.search(edf_path.name)\n",
        "    run = int(m.group(2)) if m else None\n",
        "    ev_codes = ep.events[:, 2]\n",
        "\n",
        "    is_left_run = (run in RUN_LEFT)\n",
        "    y_file = np.where(is_left_run & (ev_codes == 2), 1, 0).astype(np.int64)\n",
        "\n",
        "    return X_file, y_file, eeg_inds\n",
        "\n",
        "\n",
        "Xs, ys = [], []\n",
        "EEG_CHANNEL = None\n",
        "sample_raw_data = None\n",
        "\n",
        "all_paths = paths_left + paths_rest\n",
        "for i, p in enumerate(all_paths):\n",
        "    Xf, yf, eeg_inds = process_file_build_xy(p)\n",
        "    Xs.append(Xf)\n",
        "    ys.append(yf)\n",
        "    if EEG_CHANNEL is None:\n",
        "        EEG_CHANNEL = int(len(eeg_inds))\n",
        "    if sample_raw_data is None:\n",
        "        raw_tmp = mne.io.read_raw_edf(str(p), preload=True, stim_channel='auto', verbose='ERROR')\n",
        "        ch0 = mne.pick_types(raw_tmp.info, eeg=True)[0]\n",
        "        sample_raw_data = raw_tmp.get_data()[ch0, :500]\n",
        "\n",
        "X = np.concatenate(Xs, axis=0)\n",
        "y = np.concatenate(ys, axis=0)\n",
        "\n",
        "print(f\"X final: {X.shape}  | y: {y.shape}  | EEG_CHANNEL={EEG_CHANNEL}\")\n",
        "print(f\"LEFT (1): {(y==1).sum()}  | REST (0): {(y==0).sum()}\")\n",
        "\n",
        "\n",
        "CLASSES = [\"rest\", \"left\"]\n"
      ],
      "metadata": {
        "id": "2w-ju9hrw23O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGDataset(data.Dataset):\n",
        "    def __init__(self, x, y=None, inference=False):\n",
        "        super().__init__()\n",
        "\n",
        "        N_SAMPLE = x.shape[0]\n",
        "        val_idx = int(0.9 * N_SAMPLE)\n",
        "        train_idx = int(0.81 * N_SAMPLE)\n",
        "\n",
        "        if not inference:\n",
        "            self.train_ds = {\n",
        "                'x': x[:train_idx],\n",
        "                'y': y[:train_idx],\n",
        "            }\n",
        "            self.val_ds = {\n",
        "                'x': x[train_idx:val_idx],\n",
        "                'y': y[train_idx:val_idx],\n",
        "            }\n",
        "            self.test_ds = {\n",
        "                'x': x[val_idx:],\n",
        "                'y': y[val_idx:],\n",
        "            }\n",
        "        else:\n",
        "            self.__split = \"inference\"\n",
        "            self.inference_ds = {\n",
        "                'x': [x],\n",
        "            }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset['x'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x = self.dataset['x'][idx]\n",
        "        if self.__split != \"inference\":\n",
        "            y = self.dataset['y'][idx]\n",
        "            x = torch.tensor(x).float()\n",
        "            y = torch.tensor(y).unsqueeze(-1).float()\n",
        "            return x, y\n",
        "        else:\n",
        "            x = torch.tensor(x).float()\n",
        "            return x\n",
        "\n",
        "    def split(self, __split):\n",
        "        self.__split = __split\n",
        "        return self\n",
        "\n",
        "    @classmethod\n",
        "    def inference_dataset(cls, x):\n",
        "        return cls(x, inference=True)\n",
        "\n",
        "    @property\n",
        "    def dataset(self):\n",
        "        assert self.__split is not None, \"Please specify the split of dataset!\"\n",
        "\n",
        "        if self.__split == \"train\":\n",
        "            return self.train_ds\n",
        "        elif self.__split == \"val\":\n",
        "            return self.val_ds\n",
        "        elif self.__split == \"test\":\n",
        "            return self.test_ds\n",
        "        elif self.__split == \"inference\":\n",
        "            return self.inference_ds\n",
        "        else:\n",
        "            raise TypeError(\"Unknown type of split!\")"
      ],
      "metadata": {
        "id": "h3yJBJDqxLFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_dataset = EEGDataset(x=X, y=y)"
      ],
      "metadata": {
        "id": "LPz1_7gQxNZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(sample_raw_data)\n",
        "plt.title(\"Raw EEG, electrode 0, samples 0-500\")\n",
        "plt.ylabel(\"mV\")\n",
        "plt.xlabel(\"Sample\")\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "o9BQjh1LxPcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X[18:21, 0, :].T)\n",
        "plt.title(\"Exemplar single-trial epoched data, for electrode 0\")\n",
        "plt.ylabel(\"V\")\n",
        "plt.xlabel(\"Epoched Sample\")\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "55AajEVPxRVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del edf_files, pat, paths_left, paths_rest, all_paths, Xs, ys, Xf, yf, eeg_inds, raw_tmp\n"
      ],
      "metadata": {
        "id": "fhtN1jBBxT8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AvgMeter(object):\n",
        "    def __init__(self, num=40):\n",
        "        self.num = num\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.losses = []\n",
        "\n",
        "    def update(self, val):\n",
        "        self.losses.append(val)\n",
        "\n",
        "    def show(self):\n",
        "        out = torch.mean(\n",
        "            torch.stack(\n",
        "                self.losses[np.maximum(len(self.losses)-self.num, 0):]\n",
        "            )\n",
        "        )\n",
        "        return out"
      ],
      "metadata": {
        "id": "JvQO-p0Excil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper(L.LightningModule):\n",
        "    def __init__(self, arch, dataset, batch_size, lr, max_epoch):\n",
        "        super().__init__()\n",
        "\n",
        "        self.arch = arch\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.max_epoch = max_epoch\n",
        "\n",
        "        self.train_accuracy = Accuracy(task=\"binary\")\n",
        "        self.val_accuracy = Accuracy(task=\"binary\")\n",
        "        self.test_accuracy = Accuracy(task=\"binary\")\n",
        "\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "        self.train_acc = []\n",
        "        self.val_acc = []\n",
        "\n",
        "        self.train_loss_recorder = AvgMeter()\n",
        "        self.val_loss_recorder = AvgMeter()\n",
        "\n",
        "        self.train_acc_recorder = AvgMeter()\n",
        "        self.val_acc_recorder = AvgMeter()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.arch(x)\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        self.train_accuracy.update(y_hat, y)\n",
        "        acc = self.train_accuracy.compute().data.cpu()\n",
        "\n",
        "        opt = self.optimizers()\n",
        "        opt.zero_grad()\n",
        "        self.manual_backward(loss)\n",
        "        opt.step()\n",
        "\n",
        "        self.train_loss_recorder.update(loss.data)\n",
        "        self.train_acc_recorder.update(acc)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        sch = self.lr_schedulers()\n",
        "        sch.step()\n",
        "\n",
        "        self.train_loss.append(self.train_loss_recorder.show().data.cpu().numpy())\n",
        "        self.train_loss_recorder = AvgMeter()\n",
        "\n",
        "        self.train_acc.append(self.train_acc_recorder.show().data.cpu().numpy())\n",
        "        self.train_acc_recorder = AvgMeter()\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        self.val_accuracy.update(y_hat, y)\n",
        "        acc = self.val_accuracy.compute().data.cpu()\n",
        "\n",
        "        self.val_loss_recorder.update(loss.data)\n",
        "        self.val_acc_recorder.update(acc)\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.val_loss.append(self.val_loss_recorder.show().data.cpu().numpy())\n",
        "        self.val_loss_recorder = AvgMeter()\n",
        "\n",
        "        self.val_acc.append(self.val_acc_recorder.show().data.cpu().numpy())\n",
        "        self.val_acc_recorder = AvgMeter()\n",
        "\n",
        "    def test_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        self.test_accuracy.update(y_hat, y)\n",
        "\n",
        "        self.log(\n",
        "            \"test_loss\",\n",
        "            loss,\n",
        "            prog_bar=True,\n",
        "            logger=True,\n",
        "        )\n",
        "        self.log(\n",
        "            \"test_acc\",\n",
        "            self.test_accuracy.compute(),\n",
        "            prog_bar=True,\n",
        "            logger=True,\n",
        "        )\n",
        "\n",
        "    def on_train_end(self):\n",
        "\n",
        "        # Loss\n",
        "        loss_img_file = \"/content/loss_plot.png\"\n",
        "        plt.plot(self.train_loss, color = 'r', label='train')\n",
        "        plt.plot(self.val_loss, color = 'b', label='validation')\n",
        "        plt.title(\"Loss Curves\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.savefig(loss_img_file)\n",
        "        plt.clf()\n",
        "        img = cv2.imread(loss_img_file)\n",
        "        cv2_imshow(img)\n",
        "\n",
        "        # Accuracy\n",
        "        acc_img_file = \"/content/acc_plot.png\"\n",
        "        plt.plot(self.train_acc, color = 'r', label='train')\n",
        "        plt.plot(self.val_acc, color = 'b', label='validation')\n",
        "        plt.title(\"Accuracy Curves\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.savefig(acc_img_file)\n",
        "        plt.clf()\n",
        "        img = cv2.imread(acc_img_file)\n",
        "        cv2_imshow(img)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return data.DataLoader(\n",
        "            dataset=self.dataset.split(\"train\"),\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return data.DataLoader(\n",
        "            dataset=self.dataset.split(\"val\"),\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return data.DataLoader(\n",
        "            dataset=self.dataset.split(\"test\"),\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "\n",
        "        optimizer = optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=self.lr,\n",
        "        )\n",
        "        lr_scheduler = {\n",
        "            \"scheduler\": optim.lr_scheduler.MultiStepLR(\n",
        "                optimizer,\n",
        "                milestones=[\n",
        "                    int(self.max_epoch * 0.25),\n",
        "                    int(self.max_epoch * 0.5),\n",
        "                    int(self.max_epoch * 0.75),\n",
        "                ],\n",
        "                gamma=0.1\n",
        "            ),\n",
        "            \"name\": \"lr_scheduler\",\n",
        "        }\n",
        "        return [optimizer], [lr_scheduler]"
      ],
      "metadata": {
        "id": "p7FsXpaoxekU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Positional encoding.\n",
        "    https://d2l.ai/chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html\n",
        "    \"\"\"\n",
        "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Create a long enough P\n",
        "        self.p = torch.zeros((1, max_len, num_hiddens))\n",
        "        x = torch.arange(max_len, dtype=torch.float32).reshape(\n",
        "            -1, 1) / torch.pow(10000, torch.arange(\n",
        "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
        "        self.p[:, :, 0::2] = torch.sin(x)\n",
        "        self.p[:, :, 1::2] = torch.cos(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.p[:, :x.shape[1], :].to(x.device)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "QNkjX08ixgxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dim_feedforward, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, dim_feedforward),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim_feedforward, embed_dim),\n",
        "        )\n",
        "\n",
        "        self.layernorm0 = nn.LayerNorm(embed_dim)\n",
        "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        y, att = self.attention(x, x, x)\n",
        "        y = F.dropout(y, self.dropout, training=self.training)\n",
        "        x = self.layernorm0(x + y)\n",
        "        y = self.mlp(x)\n",
        "        y = F.dropout(y, self.dropout, training=self.training)\n",
        "        x = self.layernorm1(x + y)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kUAz1JwOxjRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGClassificationModel(nn.Module):\n",
        "    def __init__(self, eeg_channel, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                eeg_channel, eeg_channel, 11, 1, padding=5, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm1d(eeg_channel),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout1d(dropout),\n",
        "            nn.Conv1d(\n",
        "                eeg_channel, eeg_channel * 2, 11, 1, padding=5, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm1d(eeg_channel * 2),\n",
        "        )\n",
        "\n",
        "        self.transformer = nn.Sequential(\n",
        "            PositionalEncoding(eeg_channel * 2, dropout),\n",
        "            TransformerBlock(eeg_channel * 2, 4, eeg_channel // 8, dropout),\n",
        "            TransformerBlock(eeg_channel * 2, 4, eeg_channel // 8, dropout),\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(eeg_channel * 2, eeg_channel // 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(eeg_channel // 2, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = x.mean(dim=-1)\n",
        "        x = self.mlp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vg0iO8GAxlec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"EEGClassificationModel\"\n",
        "model = EEGClassificationModel(eeg_channel=EEG_CHANNEL, dropout=0.125)"
      ],
      "metadata": {
        "id": "R7xfY5iJxnsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EPOCH = 100\n",
        "BATCH_SIZE = 10\n",
        "LR = 5e-4\n",
        "CHECKPOINT_DIR = os.getcwd()\n",
        "SEED = int(np.random.randint(2147483647))\n",
        "\n",
        "print(f\"Random seed: {SEED}\")\n",
        "\n",
        "model = ModelWrapper(model, eeg_dataset, BATCH_SIZE, LR, MAX_EPOCH)\n",
        "\n",
        "!rm -rf logs/"
      ],
      "metadata": {
        "id": "dZMz0YnYxrWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboardlogger = TensorBoardLogger(save_dir=\"logs/\")\n",
        "csvlogger = CSVLogger(save_dir=\"logs/\")\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
        "checkpoint = ModelCheckpoint(\n",
        "    monitor='val_acc',\n",
        "    dirpath=CHECKPOINT_DIR,\n",
        "    mode='max',\n",
        ")\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_acc\", min_delta=0.00, patience=3, verbose=False, mode=\"max\"\n",
        ")\n",
        "\n",
        "\n",
        "seed_everything(SEED, workers=True)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    max_epochs=MAX_EPOCH,\n",
        "    logger=[tensorboardlogger, csvlogger],\n",
        "    callbacks=[lr_monitor, checkpoint, early_stopping],\n",
        "    log_every_n_steps=5,\n",
        ")\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "id": "5IssZzlHxu9Z",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(ckpt_path=\"best\")\n",
        "\n",
        "os.rename(\n",
        "    checkpoint.best_model_path,\n",
        "    os.path.join(CHECKPOINT_DIR, f\"{MODEL_NAME}_best.ckpt\")\n",
        ")"
      ],
      "metadata": {
        "id": "lNaoGtoZxza0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "    N_SAMPLE = X.shape[0]\n",
        "    sample_idx = random.randint(0, N_SAMPLE - 1)\n",
        "    sample = X[sample_idx]\n",
        "\n",
        "    trainer = Trainer()\n",
        "    prediction = trainer.predict(\n",
        "        model=model,\n",
        "        dataloaders=data.DataLoader(\n",
        "            dataset=EEGDataset.inference_dataset(X[sample_idx]),\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "        ),\n",
        "        ckpt_path=os.path.join(CHECKPOINT_DIR, f\"{MODEL_NAME}_best.ckpt\"),\n",
        "    )[0]\n",
        "\n",
        "    PREDICTED = [CLASSES[int(torch.sigmoid(prediction) > 0.5)], torch.sigmoid(prediction)]\n",
        "    ACTUAL = CLASSES[y[sample_idx]]\n",
        "    print(\"\\n\\n\\n\")\n",
        "    print(f\"Imagining {PREDICTED[0]} hand movement!\")\n",
        "    print(f\"Ground-truth: {ACTUAL}!\")\n",
        "\n",
        "    plt.plot(sample.T)\n",
        "    plt.title(\n",
        "        f\"Exemplar of epoched data, for electrode 0-63\\nActual Label : {ACTUAL}\\nPredicted Label : {PREDICTED[0]} \\nP:{PREDICTED[1]}\"\n",
        "    )\n",
        "    plt.ylabel(\"V\")\n",
        "    plt.xlabel(\"Epoched Sample\")\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    print(\"\\n\\n\\n\")\n"
      ],
      "metadata": {
        "id": "8rweL0Kox1XZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}