{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6921363,
          "sourceType": "datasetVersion",
          "datasetId": 3950037
        }
      ],
      "dockerImageVersionId": 30886,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook53768553d1",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emitejadaa/NeuroLinked/blob/main/eegKumarImaginatedSpeech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ignazio_kumars_eeg_imagined_speech_path = kagglehub.dataset_download('ignazio/kumars-eeg-imagined-speech')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "UrWCXu43rYRL",
        "outputId": "53ce1073-b886-43f1-eec7-5b9c99365ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ignazio/kumars-eeg-imagined-speech?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.9M/21.9M [00:00<00:00, 115MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "hIlBoc25rYRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T17:53:22.411508Z",
          "iopub.execute_input": "2025-02-23T17:53:22.411819Z",
          "iopub.status.idle": "2025-02-23T17:53:26.522322Z",
          "shell.execute_reply.started": "2025-02-23T17:53:22.411792Z",
          "shell.execute_reply": "2025-02-23T17:53:26.521303Z"
        },
        "id": "awybSXnzrYRN",
        "outputId": "0ce48755-ac60-416f-b165-eea38d3830e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.10.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "Downloading mne-1.10.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.10.1\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T17:53:27.437693Z",
          "iopub.execute_input": "2025-02-23T17:53:27.437948Z",
          "iopub.status.idle": "2025-02-23T17:53:30.919064Z",
          "shell.execute_reply.started": "2025-02-23T17:53:27.437926Z",
          "shell.execute_reply": "2025-02-23T17:53:30.918254Z"
        },
        "id": "t6-iL8sSrYRO",
        "outputId": "8896d501-0f69-4ea6-bb94-02cea9caa966",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\n",
            "Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries Used"
      ],
      "metadata": {
        "id": "s5DyDO5zrYRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T19:21:11.069757Z",
          "iopub.execute_input": "2025-02-23T19:21:11.070052Z",
          "iopub.status.idle": "2025-02-23T19:21:11.378218Z",
          "shell.execute_reply.started": "2025-02-23T19:21:11.070009Z",
          "shell.execute_reply": "2025-02-23T19:21:11.377369Z"
        },
        "id": "_0031Z7XrYRP"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set the dataset root directory (update if necessary)\n",
        "# DATASET_ROOT = '/kaggle/input/kumars-eeg-imagined-speech/Imagined_speech_EEG_edf'\n",
        "\n",
        "# # Loop through each folder and list files\n",
        "# for folder in [\"Char\", \"Digit\", \"Image\"]:\n",
        "#     folder_path = os.path.join(DATASET_ROOT, folder)\n",
        "\n",
        "#     if os.path.exists(folder_path):\n",
        "#         print(f\"\\nFiles in {folder} folder:\")\n",
        "#         files = os.listdir(folder_path)\n",
        "\n",
        "#         for file in files:\n",
        "#             print(file)\n",
        "#     else:\n",
        "#         print(f\"\\nWarning: Folder {folder} not found!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-22T13:43:54.072691Z",
          "iopub.execute_input": "2025-02-22T13:43:54.072962Z",
          "iopub.status.idle": "2025-02-22T13:43:54.076439Z",
          "shell.execute_reply.started": "2025-02-22T13:43:54.07294Z",
          "shell.execute_reply": "2025-02-22T13:43:54.075549Z"
        },
        "id": "fyQwjJKjrYRP"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Dataset"
      ],
      "metadata": {
        "id": "Cvsm3kljrYRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting and Oreprocessing Data"
      ],
      "metadata": {
        "id": "p6FlWOXYrYRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RrpgzxN-r2nS",
        "outputId": "23a1f889-939b-4ddd-96c9-1c903ea28baf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = '/content/drive/MyDrive/Colab-Dataset/eegData'\n",
        "\n",
        "# Define folders and their corresponding classes\n",
        "folders = {\n",
        "    'Char': {\n",
        "        'path': os.path.join(DATASET_ROOT, 'Char'),\n",
        "        'classes': ['A', 'C', 'F', 'H', 'J', 'M', 'P', 'S', 'T', 'Y']\n",
        "    },\n",
        "    'Digit': {\n",
        "        'path': os.path.join(DATASET_ROOT, 'Digit'),\n",
        "        'classes': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "    },\n",
        "    'Image': {\n",
        "        'path': os.path.join(DATASET_ROOT, 'Image'),\n",
        "        'classes': ['Apple', 'Car', 'Dog', 'Gold', 'Mobile', 'Rose', 'Scooter', 'Tiger', 'Wallet', 'Watch']\n",
        "    }\n",
        "}\n",
        "\n",
        "char_labels_index_mapping = {\n",
        "    'Char_A': 0,\n",
        "    'Char_C': 1,\n",
        "    'Char_F': 2,\n",
        "    'Char_H': 3,\n",
        "    'Char_J': 4,\n",
        "    'Char_M': 5,\n",
        "    'Char_P': 6,\n",
        "    'Char_S': 7,\n",
        "    'Char_T': 8,\n",
        "    'Char_Y': 9\n",
        "}\n",
        "\n",
        "digit_labels_index_mapping = {\n",
        "    'Digit_0': 0,\n",
        "    'Digit_1': 1,\n",
        "    'Digit_2': 2,\n",
        "    'Digit_3': 3,\n",
        "    'Digit_4': 4,\n",
        "    'Digit_5': 5,\n",
        "    'Digit_6': 6,\n",
        "    'Digit_7': 7,\n",
        "    'Digit_8': 8,\n",
        "    'Digit_9': 9\n",
        "}\n",
        "\n",
        "image_labels_index_mapping = {\n",
        "    'Image_Apple': 0,\n",
        "    'Image_Car': 1,\n",
        "    'Image_Dog': 2,\n",
        "    'Image_Gold': 3,\n",
        "    'Image_Mobile': 4,\n",
        "    'Image_Rose': 5,\n",
        "    'Image_Scooter': 6,\n",
        "    'Image_Tiger': 7,\n",
        "    'Image_Wallet': 8,\n",
        "    'Image_Watch': 9\n",
        "}\n",
        "\n",
        "char_data = None\n",
        "char_labels = np.array([], dtype=np.int32)\n",
        "\n",
        "digit_data = None\n",
        "digit_labels = np.array([], dtype=np.int32)\n",
        "\n",
        "image_data = None\n",
        "image_labels = np.array([], dtype=np.int32)\n",
        "\n",
        "min_timepoints = 1408\n",
        "# Loop over folders and read each EDF file\n",
        "for folder_key, info in folders.items():\n",
        "    folder_path = info['path']\n",
        "    file_list = [fname for fname in os.listdir(folder_path)]\n",
        "    for file in file_list:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "\n",
        "        # Reading and preprocessing raw data\n",
        "        raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
        "        # Highpass filtering above 0.5 Hz\n",
        "        raw.filter(l_freq=0.5, h_freq = 60, method='iir', verbose=False)\n",
        "        # Notch filter for Removal of Line Voltage Noise\n",
        "        raw.notch_filter(freqs=50, verbose=False)\n",
        "\n",
        "        data = raw.get_data()\n",
        "        n_times = data.shape[1]\n",
        "        data = (raw.get_data())[:, :min_timepoints]\n",
        "        # Labels\n",
        "        parts = file.split('_')\n",
        "        file_label = parts[1].replace('.edf', '')\n",
        "        if folder_key == 'Image':\n",
        "            file_label = file_label.capitalize()\n",
        "        class_name = f\"{folder_key}_{file_label}\"\n",
        "\n",
        "        if folder_key == 'Char':\n",
        "            label = char_labels_index_mapping[class_name]\n",
        "            char_labels = np.append(char_labels, label)\n",
        "            if char_data is None:\n",
        "                char_data = data[np.newaxis, ...]\n",
        "            else:\n",
        "                char_data = np.concatenate((char_data, data[np.newaxis, ...]), axis=0)\n",
        "\n",
        "        elif folder_key == 'Digit':\n",
        "            label = digit_labels_index_mapping[class_name]\n",
        "            digit_labels = np.append(digit_labels, label)\n",
        "            if digit_data is None:\n",
        "                digit_data = data[np.newaxis, ...]\n",
        "            else:\n",
        "                digit_data = np.concatenate((digit_data, data[np.newaxis, ...]), axis=0)\n",
        "\n",
        "        elif folder_key == 'Image':\n",
        "            label = image_labels_index_mapping[class_name]\n",
        "            image_labels = np.append(image_labels, label)\n",
        "            if image_data is None:\n",
        "                image_data = data[np.newaxis, ...]\n",
        "            else:\n",
        "                image_data = np.concatenate((image_data, data[np.newaxis, ...]), axis=0)\n",
        "\n",
        "print(\"Char Data Dimention:\")\n",
        "print(char_data.shape)\n",
        "print(char_labels.shape)\n",
        "print(\"Digit Data Dimention:\")\n",
        "print(digit_data.shape)\n",
        "print(digit_labels.shape)\n",
        "print(\"Image Data Dimention:\")\n",
        "print(image_data.shape)\n",
        "print(image_labels.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T17:54:05.910548Z",
          "iopub.execute_input": "2025-02-23T17:54:05.910987Z",
          "iopub.status.idle": "2025-02-23T17:54:52.212189Z",
          "shell.execute_reply.started": "2025-02-23T17:54:05.910962Z",
          "shell.execute_reply": "2025-02-23T17:54:52.211403Z"
        },
        "id": "3ehCVFMPrYRQ",
        "outputId": "cd796c11-836f-4a78-f569-774ed077207a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Char Data Dimention:\n",
            "(230, 39, 1408)\n",
            "(230,)\n",
            "Digit Data Dimention:\n",
            "(230, 39, 1408)\n",
            "(230,)\n",
            "Image Data Dimention:\n",
            "(230, 39, 1408)\n",
            "(230,)\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structuring Data"
      ],
      "metadata": {
        "id": "YEMR8KCErYRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    dataset_type = input(\"Choose the dataset (Char, Digit, Image): \").strip().lower()\n",
        "    if dataset_type == \"char\":\n",
        "        data = char_data\n",
        "        labels = char_labels\n",
        "        break\n",
        "    elif dataset_type == \"digit\":\n",
        "        data = digit_data\n",
        "        labels = digit_labels\n",
        "        break\n",
        "    elif dataset_type == \"image\":\n",
        "        data = image_data\n",
        "        labels = image_labels\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid input, please try again!\")\n",
        "\n",
        "X = (data - np.mean(data)) / np.std(data)\n",
        "y = labels\n",
        "\n",
        "# Spliting  Data: 80% for Train and 20% for Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Choosing Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Converting to Tensor\n",
        "X_train = torch.Tensor(X_train).to(device)\n",
        "X_test = torch.Tensor(X_test).to(device)\n",
        "y_train = torch.LongTensor(y_train).to(device)\n",
        "y_test = torch.LongTensor(y_test).to(device)\n",
        "\n",
        "# Creating Tensor Dataset\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Printing the sizes\n",
        "print(\"Size of X_train:\", X_train.size())\n",
        "print(\"Size of X_test:\", X_test.size())\n",
        "print(\"Size of y_train:\", y_train.size())\n",
        "print(\"Size of y_test:\", y_test.size())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T18:51:24.211227Z",
          "iopub.execute_input": "2025-02-23T18:51:24.211547Z",
          "iopub.status.idle": "2025-02-23T18:51:27.455852Z",
          "shell.execute_reply.started": "2025-02-23T18:51:24.211522Z",
          "shell.execute_reply": "2025-02-23T18:51:27.455055Z"
        },
        "id": "Usam5G7nrYRR",
        "outputId": "c46828af-dd1b-46b3-a632-0635764f2614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose the dataset (Char, Digit, Image): Char\n",
            "Size of X_train: torch.Size([184, 39, 1408])\n",
            "Size of X_test: torch.Size([46, 39, 1408])\n",
            "Size of y_train: torch.Size([184])\n",
            "Size of y_test: torch.Size([46])\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Class"
      ],
      "metadata": {
        "id": "dVvvxN4MrYRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainModel():\n",
        "    def __init__(self,):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def train_model(self, model, train_dataset, learning_rate=0.001, batch_size=64, epochs=100):\n",
        "        model = model.to(self.device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        mse_loss = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        highest_train_accuracy = 0.0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                recon, outputs = model(inputs)\n",
        "                recon_loss = mse_loss(recon, inputs)\n",
        "                class_loss = criterion(outputs, labels)\n",
        "                loss = recon_loss + class_loss\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            epoch_loss = running_loss / len(train_loader.dataset)\n",
        "            epoch_accuracy = correct / total\n",
        "            if epoch_accuracy > highest_train_accuracy:\n",
        "                highest_train_accuracy = epoch_accuracy\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {(epoch_accuracy*100):.2f}%\")\n",
        "\n",
        "        average_loss = running_loss / len(train_loader.dataset)\n",
        "        print(\"Average Loss:\", average_loss)\n",
        "        print(\"Highest Train Accuracy:\", highest_train_accuracy)\n",
        "\n",
        "        # Saving model\n",
        "        torch.save(model.state_dict(), 'eegnet_model.pth')\n",
        "        return model\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T18:52:13.503286Z",
          "iopub.execute_input": "2025-02-23T18:52:13.503559Z",
          "iopub.status.idle": "2025-02-23T18:52:13.512235Z",
          "shell.execute_reply.started": "2025-02-23T18:52:13.503537Z",
          "shell.execute_reply": "2025-02-23T18:52:13.511375Z"
        },
        "id": "AfXjVOsZrYRR"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Model"
      ],
      "metadata": {
        "id": "APSwUWlurYRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EvalModel():\n",
        "    def __init__(self, model):\n",
        "        self.model = model.to(device)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    def test_model(self, test_dataset):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                recon, outputs = self.model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = (correct / total) * 100\n",
        "        print(\"/------------------------------/\")\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "        print(\"/------------------------------/\")\n",
        "        return accuracy\n",
        "\n",
        "    def plot_confusion_matrix(self, test_dataset, classes):\n",
        "        self.model.eval()\n",
        "        y_pred = []\n",
        "        y_true = []\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                recon, outputs = self.model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                y_pred.append(predicted.item())\n",
        "                y_true.append(labels.item())\n",
        "\n",
        "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "        cf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        df_cm = pd.DataFrame(cf_matrix, index=classes, columns=classes)\n",
        "\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='.2f')\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.savefig('confusion_matrix_model.png')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T19:20:36.150805Z",
          "iopub.execute_input": "2025-02-23T19:20:36.15113Z",
          "iopub.status.idle": "2025-02-23T19:20:36.159651Z",
          "shell.execute_reply.started": "2025-02-23T19:20:36.151102Z",
          "shell.execute_reply": "2025-02-23T19:20:36.158863Z"
        },
        "id": "F0NUbCxXrYRS"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDL Model"
      ],
      "metadata": {
        "id": "1A8YE2VErYRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SDLModel(nn.Module):\n",
        "    def __init__(self, channels=39, time_points=1408, classes=10, latent_dim=128, f1=64, t_layers=2, nhead=4):\n",
        "        super(SDLModel, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_conv = nn.Sequential(\n",
        "            nn.Conv1d(channels, f1, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(f1, f1 * 2, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.reduced_length = time_points // 4\n",
        "        feature_dim = f1 * 2  # 128\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=feature_dim, nhead=nhead, batch_first=False)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=t_layers)\n",
        "\n",
        "        self.fc_enc = nn.Linear(feature_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc_dec = nn.Linear(latent_dim, feature_dim * self.reduced_length)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=feature_dim, nhead=nhead, batch_first=False)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=t_layers)\n",
        "\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose1d(feature_dim, f1, kernel_size=3, stride=2, padding=1, output_padding=1),  # [B, 64, 704]\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(f1, channels, kernel_size=3, stride=2, padding=1, output_padding=1),     # [B, 39, 1408]\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Linear(latent_dim, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc = self.encoder_conv(x)\n",
        "        enc_t = enc.permute(2, 0, 1)\n",
        "        enc_transformed = self.transformer_encoder(enc_t)\n",
        "        enc_mean = enc_transformed.mean(dim=0)\n",
        "        latent = self.fc_enc(enc_mean)\n",
        "\n",
        "        # Decoder\n",
        "        dec_input = self.fc_dec(latent)\n",
        "        dec_input = dec_input.view(-1, self.reduced_length, enc.size(1))\n",
        "        dec_input_t = dec_input.permute(1, 0, 2)\n",
        "        dec_transformed = self.transformer_decoder(dec_input_t, enc_transformed)\n",
        "        dec_features = dec_transformed.permute(1, 2, 0)\n",
        "        recon = self.decoder_conv(dec_features)\n",
        "\n",
        "        # Classifier\n",
        "        class_logits = self.classifier(latent)\n",
        "\n",
        "        return recon, class_logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T18:51:36.720431Z",
          "iopub.execute_input": "2025-02-23T18:51:36.720715Z",
          "iopub.status.idle": "2025-02-23T18:51:36.729316Z",
          "shell.execute_reply.started": "2025-02-23T18:51:36.720692Z",
          "shell.execute_reply": "2025-02-23T18:51:36.72849Z"
        },
        "id": "nlSEba4crYRS"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Summery"
      ],
      "metadata": {
        "id": "_eAbXAhyrYRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (39, 1408)\n",
        "sdl_model = SDLModel().to(device)\n",
        "summary(sdl_model, input_size)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T18:51:38.421277Z",
          "iopub.execute_input": "2025-02-23T18:51:38.421575Z",
          "iopub.status.idle": "2025-02-23T18:51:38.532782Z",
          "shell.execute_reply.started": "2025-02-23T18:51:38.421549Z",
          "shell.execute_reply": "2025-02-23T18:51:38.532001Z"
        },
        "id": "28RyWE3qrYRS",
        "outputId": "70ea65c7-9823-4c7d-f8ee-fad82c0b593e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "├─Sequential: 1-1                             [-1, 128, 352]            --\n",
            "|    └─Conv1d: 2-1                            [-1, 64, 704]             7,552\n",
            "|    └─ReLU: 2-2                              [-1, 64, 704]             --\n",
            "|    └─Conv1d: 2-3                            [-1, 128, 352]            24,704\n",
            "|    └─ReLU: 2-4                              [-1, 128, 352]            --\n",
            "├─TransformerEncoder: 1-2                     [-1, 2, 128]              --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─TransformerEncoderLayer: 3-1      [-1, 2, 128]              593,024\n",
            "|    |    └─TransformerEncoderLayer: 3-2      [-1, 2, 128]              593,024\n",
            "├─Linear: 1-3                                 [-1, 128]                 16,512\n",
            "├─Linear: 1-4                                 [-1, 45056]               5,812,224\n",
            "├─TransformerDecoder: 1-5                     [-1, 2, 128]              --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─TransformerDecoderLayer: 3-3      [-1, 2, 128]              659,328\n",
            "|    |    └─TransformerDecoderLayer: 3-4      [-1, 2, 128]              659,328\n",
            "├─Sequential: 1-6                             [-1, 39, 1408]            --\n",
            "|    └─ConvTranspose1d: 2-5                   [-1, 64, 704]             24,640\n",
            "|    └─ReLU: 2-6                              [-1, 64, 704]             --\n",
            "|    └─ConvTranspose1d: 2-7                   [-1, 39, 1408]            7,527\n",
            "├─Linear: 1-7                                 [-1, 10]                  1,290\n",
            "===============================================================================================\n",
            "Total params: 8,399,153\n",
            "Trainable params: 8,399,153\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 55.09\n",
            "===============================================================================================\n",
            "Input size (MB): 0.21\n",
            "Forward/backward pass size (MB): 1.95\n",
            "Params size (MB): 32.04\n",
            "Estimated Total Size (MB): 34.20\n",
            "===============================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "├─Sequential: 1-1                             [-1, 128, 352]            --\n",
              "|    └─Conv1d: 2-1                            [-1, 64, 704]             7,552\n",
              "|    └─ReLU: 2-2                              [-1, 64, 704]             --\n",
              "|    └─Conv1d: 2-3                            [-1, 128, 352]            24,704\n",
              "|    └─ReLU: 2-4                              [-1, 128, 352]            --\n",
              "├─TransformerEncoder: 1-2                     [-1, 2, 128]              --\n",
              "|    └─ModuleList: 2                          []                        --\n",
              "|    |    └─TransformerEncoderLayer: 3-1      [-1, 2, 128]              593,024\n",
              "|    |    └─TransformerEncoderLayer: 3-2      [-1, 2, 128]              593,024\n",
              "├─Linear: 1-3                                 [-1, 128]                 16,512\n",
              "├─Linear: 1-4                                 [-1, 45056]               5,812,224\n",
              "├─TransformerDecoder: 1-5                     [-1, 2, 128]              --\n",
              "|    └─ModuleList: 2                          []                        --\n",
              "|    |    └─TransformerDecoderLayer: 3-3      [-1, 2, 128]              659,328\n",
              "|    |    └─TransformerDecoderLayer: 3-4      [-1, 2, 128]              659,328\n",
              "├─Sequential: 1-6                             [-1, 39, 1408]            --\n",
              "|    └─ConvTranspose1d: 2-5                   [-1, 64, 704]             24,640\n",
              "|    └─ReLU: 2-6                              [-1, 64, 704]             --\n",
              "|    └─ConvTranspose1d: 2-7                   [-1, 39, 1408]            7,527\n",
              "├─Linear: 1-7                                 [-1, 10]                  1,290\n",
              "===============================================================================================\n",
              "Total params: 8,399,153\n",
              "Trainable params: 8,399,153\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 55.09\n",
              "===============================================================================================\n",
              "Input size (MB): 0.21\n",
              "Forward/backward pass size (MB): 1.95\n",
              "Params size (MB): 32.04\n",
              "Estimated Total Size (MB): 34.20\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "puFTcyTGrYRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdl_model = SDLModel().to(device)\n",
        "\n",
        "# Training Hyperparameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "trainer = TrainModel()\n",
        "trained_sdl_model = trainer.train_model(sdl_model, train_dataset, learning_rate=LEARNING_RATE,\n",
        "                                   batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "torch.save(trained_sdl_model.state_dict(), 'eegnet_model.pth')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T18:53:23.141385Z",
          "iopub.execute_input": "2025-02-23T18:53:23.141671Z",
          "iopub.status.idle": "2025-02-23T18:54:34.283444Z",
          "shell.execute_reply.started": "2025-02-23T18:53:23.141649Z",
          "shell.execute_reply": "2025-02-23T18:54:34.282482Z"
        },
        "id": "y6IGyz9UrYRT",
        "outputId": "00dae641-6939-43a4-b376-1ebefb5a6140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 3.5567, Accuracy: 7.61%\n",
            "Epoch 2/100, Loss: 3.3390, Accuracy: 7.61%\n",
            "Epoch 3/100, Loss: 3.2929, Accuracy: 7.07%\n",
            "Epoch 4/100, Loss: 3.2904, Accuracy: 9.78%\n",
            "Epoch 5/100, Loss: 3.2595, Accuracy: 9.78%\n",
            "Epoch 6/100, Loss: 3.2575, Accuracy: 9.24%\n",
            "Epoch 7/100, Loss: 3.2605, Accuracy: 11.96%\n",
            "Epoch 8/100, Loss: 3.2688, Accuracy: 10.87%\n",
            "Epoch 9/100, Loss: 3.2565, Accuracy: 12.50%\n",
            "Epoch 10/100, Loss: 3.2654, Accuracy: 9.78%\n",
            "Epoch 11/100, Loss: 3.2599, Accuracy: 10.33%\n",
            "Epoch 12/100, Loss: 3.2526, Accuracy: 10.33%\n",
            "Epoch 13/100, Loss: 3.2496, Accuracy: 10.87%\n",
            "Epoch 14/100, Loss: 3.2490, Accuracy: 10.87%\n",
            "Epoch 15/100, Loss: 3.2502, Accuracy: 7.61%\n",
            "Epoch 16/100, Loss: 3.2420, Accuracy: 10.33%\n",
            "Epoch 17/100, Loss: 3.2333, Accuracy: 10.87%\n",
            "Epoch 18/100, Loss: 3.2334, Accuracy: 9.24%\n",
            "Epoch 19/100, Loss: 3.2288, Accuracy: 10.33%\n",
            "Epoch 20/100, Loss: 3.2231, Accuracy: 14.67%\n",
            "Epoch 21/100, Loss: 3.2144, Accuracy: 14.13%\n",
            "Epoch 22/100, Loss: 3.2056, Accuracy: 13.04%\n",
            "Epoch 23/100, Loss: 3.2006, Accuracy: 13.59%\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Model"
      ],
      "metadata": {
        "id": "X66kcN-hrYRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model = EvalModel(trained_sdl_model)\n",
        "while True:\n",
        "    dataset_type = input(\"Choose the dataset (Char, Digit, Image): \").strip().lower()\n",
        "    if dataset_type == \"char\":\n",
        "        classes_list = ['A', 'C', 'F', 'H', 'J', 'M', 'P', 'S', 'T', 'Y']\n",
        "        break\n",
        "    elif dataset_type == \"digit\":\n",
        "        classes_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "        break\n",
        "    elif dataset_type == \"image\":\n",
        "        classes_list = ['Apple', 'Car', 'Dog', 'Gold', 'Mobile', 'Rose', 'Scooter', 'Tiger', 'Wallet', 'Watch']\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid input, please try again!\")\n",
        "test_accuracy = eval_model.test_model(test_dataset)\n",
        "eval_model.plot_confusion_matrix(test_dataset, classes_list)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-23T19:21:39.161278Z",
          "iopub.execute_input": "2025-02-23T19:21:39.161581Z",
          "iopub.status.idle": "2025-02-23T19:21:42.5869Z",
          "shell.execute_reply.started": "2025-02-23T19:21:39.161558Z",
          "shell.execute_reply": "2025-02-23T19:21:42.586087Z"
        },
        "id": "ix0dROeOrYRT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "OebvXSqsrYRT"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}